{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14aae07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f909264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhi/anaconda3/lib/python3.11/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "\n",
    "# Load MNIST dataset (70000 samples, 28x28 images)\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "\n",
    "X = mnist['data']\n",
    "y = mnist['target'].astype(np.int64)\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "X = X / 255.0\n",
    "\n",
    "# Use only first 5000 samples for now (to keep it fast)\n",
    "X = X[:5000]\n",
    "y = y[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b846fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, num_classes=10):\n",
    "    m = y.shape[0]\n",
    "    one_hot_y = np.zeros((m, num_classes))\n",
    "    one_hot_y[np.arange(m), y] = 1\n",
    "    return one_hot_y\n",
    "\n",
    "Y = one_hot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cebaca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Layer sizes\n",
    "input_size = 784\n",
    "hidden_size = 64\n",
    "output_size = 10\n",
    "\n",
    "# Weights and biases\n",
    "W1 = np.random.randn(input_size, hidden_size) * np.sqrt(1. / input_size)\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "\n",
    "W2 = np.random.randn(hidden_size, output_size) * np.sqrt(1. / hidden_size)\n",
    "b2 = np.zeros((1, output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "061cdc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # avoid overflow\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "def forward_pass(X, W1, b1, W2, b2):\n",
    "    # Hidden layer\n",
    "    Z1 = np.dot(X, W1) + b1  # shape (m, 64)\n",
    "    A1 = relu(Z1)            # shape (m, 64)\n",
    "\n",
    "    # Output layer\n",
    "    Z2 = np.dot(A1, W2) + b2  # shape (m, 10)\n",
    "    A2 = softmax(Z2)          # shape (m, 10)\n",
    "\n",
    "    return Z1, A1, Z2, A2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fad1331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2 shape: (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "Z1, A1, Z2, A2 = forward_pass(X, W1, b1, W2, b2)\n",
    "print(\"A2 shape:\", A2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c0e0b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(Y, A2):\n",
    "    m = Y.shape[0]  # number of samples\n",
    "    # Add a small epsilon (1e-8) to avoid log(0)\n",
    "    log_probs = -np.log(A2 + 1e-8)\n",
    "    loss = np.sum(Y * log_probs) / m\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc2d67cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 2.337884190806204\n"
     ]
    }
   ],
   "source": [
    "loss = compute_loss(Y, A2)\n",
    "print(\"Initial loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d094e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_derivative(Z):\n",
    "    return Z > 0  # returns 1 where Z > 0, else 0\n",
    "\n",
    "def backward_pass(X, Y, Z1, A1, Z2, A2, W2):\n",
    "    m = Y.shape[0]\n",
    "\n",
    "    # Output layer\n",
    "    dZ2 = A2 - Y                  # shape (m, 10)\n",
    "    dW2 = np.dot(A1.T, dZ2) / m   # shape (64, 10)\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m  # shape (1, 10)\n",
    "\n",
    "    # Hidden layer\n",
    "    dA1 = np.dot(dZ2, W2.T)       # shape (m, 64)\n",
    "    dZ1 = dA1 * relu_derivative(Z1)  # shape (m, 64)\n",
    "    dW1 = np.dot(X.T, dZ1) / m    # shape (784, 64)\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m  # shape (1, 64)\n",
    "\n",
    "    return dW1, db1, dW2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d44a8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 2.3379\n",
      "Epoch 100: Loss = 0.4663\n",
      "Epoch 200: Loss = 0.3366\n",
      "Epoch 300: Loss = 0.2854\n",
      "Epoch 400: Loss = 0.2538\n",
      "Epoch 500: Loss = 0.2304\n",
      "Epoch 600: Loss = 0.2111\n",
      "Epoch 700: Loss = 0.1949\n",
      "Epoch 800: Loss = 0.1808\n",
      "Epoch 900: Loss = 0.1682\n",
      "Epoch 999: Loss = 0.1570\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "learning_rate = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    Z1, A1, Z2, A2 = forward_pass(X, W1, b1, W2, b2)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = compute_loss(Y, A2)\n",
    "    \n",
    "    # Backward pass\n",
    "    dW1, db1, dW2, db2 = backward_pass(X, Y, Z1, A1, Z2, A2, W2)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    \n",
    "    # Print loss every 100 epochs\n",
    "    if epoch % 100 == 0 or epoch == epochs - 1:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6749310f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 96.04%\n"
     ]
    }
   ],
   "source": [
    "def predict(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_pass(X, W1, b1, W2, b2)\n",
    "    return np.argmax(A2, axis=1)  # class with highest probability\n",
    "\n",
    "y_pred = predict(X, W1, b1, W2, b2)\n",
    "accuracy = np.mean(y_pred == y) * 100\n",
    "print(f\"Training Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e488a5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 92.40%\n"
     ]
    }
   ],
   "source": [
    "# Test on unseen data\n",
    "X_test = mnist['data'][5000:6000] / 255.0\n",
    "y_test = mnist['target'][5000:6000].astype(np.int64)\n",
    "\n",
    "# Predict\n",
    "y_pred_test = predict(X_test, W1, b1, W2, b2)\n",
    "\n",
    "# Accuracy\n",
    "test_accuracy = np.mean(y_pred_test == y_test) * 100\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f65e4fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_image = X_test.iloc[0].values  # shape: (784,)\n",
    "true_label = y_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d48be56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1536eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_image = single_image.reshape(1, -1)  # shape: (1, 784)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8eb78798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 7, True: 7\n"
     ]
    }
   ],
   "source": [
    "predicted_label = predict(single_image, W1, b1, W2, b2)\n",
    "print(f\"Predicted: {predicted_label[0]}, True: {true_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64f5fc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 7, True: 7\n",
      "Predicted: 3, True: 3\n",
      "Predicted: 9, True: 4\n",
      "Predicted: 6, True: 6\n",
      "Predicted: 1, True: 1\n",
      "Predicted: 8, True: 8\n",
      "Predicted: 1, True: 1\n",
      "Predicted: 0, True: 0\n",
      "Predicted: 9, True: 9\n",
      "Predicted: 8, True: 8\n",
      "Predicted: 0, True: 0\n",
      "Predicted: 3, True: 3\n",
      "Predicted: 1, True: 1\n",
      "Predicted: 7, True: 2\n",
      "Predicted: 7, True: 7\n",
      "Predicted: 0, True: 0\n",
      "Predicted: 2, True: 2\n",
      "Predicted: 9, True: 9\n",
      "Predicted: 6, True: 6\n",
      "Predicted: 0, True: 0\n",
      "Predicted: 1, True: 1\n",
      "Predicted: 6, True: 6\n",
      "Predicted: 7, True: 7\n",
      "Predicted: 1, True: 1\n",
      "Predicted: 9, True: 9\n",
      "Predicted: 7, True: 7\n",
      "Predicted: 6, True: 6\n",
      "Predicted: 5, True: 5\n",
      "Predicted: 5, True: 5\n",
      "Predicted: 3, True: 8\n",
      "Predicted: 8, True: 8\n",
      "Predicted: 3, True: 3\n",
      "Predicted: 4, True: 4\n",
      "Predicted: 4, True: 4\n",
      "Predicted: 8, True: 8\n",
      "Predicted: 7, True: 7\n",
      "Predicted: 3, True: 3\n",
      "Predicted: 6, True: 6\n",
      "Predicted: 4, True: 4\n",
      "Predicted: 6, True: 6\n",
      "Predicted: 6, True: 6\n",
      "Predicted: 3, True: 3\n",
      "Predicted: 8, True: 8\n",
      "Predicted: 8, True: 8\n",
      "Predicted: 9, True: 9\n",
      "Predicted: 7, True: 9\n",
      "Predicted: 4, True: 4\n",
      "Predicted: 4, True: 4\n",
      "Predicted: 0, True: 0\n",
      "Predicted: 7, True: 7\n",
      "Predicted: 8, True: 8\n",
      "Predicted: 1, True: 1\n",
      "Predicted: 0, True: 0\n",
      "Predicted: 0, True: 0\n",
      "Predicted: 1, True: 1\n",
      "Predicted: 8, True: 8\n",
      "Predicted: 5, True: 5\n",
      "Predicted: 7, True: 7\n",
      "Predicted: 1, True: 1\n",
      "Predicted: 7, True: 7\n",
      "Predicted: 5, True: 5\n",
      "Predicted: 5, True: 5\n",
      "Predicted: 9, True: 9\n",
      "Predicted: 9, True: 9\n",
      "Predicted: 4, True: 4\n",
      "Predicted: 7, True: 2\n",
      "Predicted: 5, True: 5\n",
      "Predicted: 3, True: 3\n",
      "Predicted: 0, True: 7\n",
      "Predicted: 4, True: 4\n",
      "Predicted: 6, True: 6\n",
      "Predicted: 6, True: 6\n",
      "Predicted: 0, True: 0\n",
      "Predicted: 1, True: 1\n",
      "Predicted: 0, True: 0\n",
      "Predicted: 1, True: 1\n",
      "Predicted: 2, True: 2\n",
      "Predicted: 4, True: 4\n",
      "Predicted: 5, True: 8\n",
      "Predicted: 5, True: 5\n",
      "Predicted: 5, True: 3\n",
      "Predicted: 5, True: 5\n",
      "Predicted: 0, True: 0\n",
      "Predicted: 0, True: 0\n",
      "Predicted: 6, True: 6\n",
      "Predicted: 4, True: 4\n",
      "Predicted: 3, True: 3\n",
      "Predicted: 8, True: 8\n",
      "Predicted: 3, True: 3\n",
      "Predicted: 7, True: 7\n",
      "Predicted: 1, True: 1\n",
      "Predicted: 4, True: 4\n",
      "Predicted: 3, True: 3\n",
      "Predicted: 9, True: 9\n",
      "Predicted: 2, True: 2\n",
      "Predicted: 2, True: 2\n",
      "Predicted: 0, True: 0\n",
      "Predicted: 3, True: 3\n",
      "Predicted: 6, True: 6\n",
      "Predicted: 6, True: 6\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    single_image = X_test.iloc[i].values  # shape: (784,)\n",
    "    true_label = y_test.iloc[i]\n",
    "    single_image = single_image.reshape(1, -1)\n",
    "    predicted_label = predict(single_image, W1, b1, W2, b2)\n",
    "    print(f\"Predicted: {predicted_label[0]}, True: {true_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e192a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
